{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from IPython.display import display, clear_output\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "\n",
    "# Suppressing warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "books = pd.read_csv('data/books.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\", dtype=object)\n",
    "books.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher']\n",
    "\n",
    "users = pd.read_csv('data/users.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\n",
    "users.columns = ['userID', 'Location', 'Age']\n",
    "\n",
    "ratings = pd.read_csv('data/ratings.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\", dtype=object)\n",
    "ratings.columns = ['userID', 'ISBN', 'bookRating']\n",
    "\n",
    "# Data preprocessing\n",
    "# Handling invalid years in the 'yearOfPublication' column\n",
    "books.loc[(books.yearOfPublication.astype(np.int32) > 2006) | (books.yearOfPublication.astype(np.int32) == 0), 'yearOfPublication'] = np.NAN\n",
    "books.yearOfPublication.fillna(round(books.yearOfPublication.mean()), inplace=True)\n",
    "books.yearOfPublication = books.yearOfPublication.astype(np.int32)\n",
    "\n",
    "# Handling invalid ages in the 'Age' column\n",
    "users.loc[(users.Age > 90) | (users.Age < 5), 'Age'] = np.nan\n",
    "users.Age = users.Age.fillna(users.Age.mean())\n",
    "users.Age = users.Age.astype(np.int32)\n",
    "\n",
    "# Filtering ratings based on available books and users\n",
    "ratings.userID = ratings.userID.astype(np.int64)\n",
    "ratings.bookRating = ratings.bookRating.astype(np.int64)\n",
    "ratings_new = ratings[ratings.ISBN.isin(books.ISBN)]\n",
    "ratings = ratings[ratings.userID.isin(users.userID)]\n",
    "\n",
    "# Displaying some information about the dataset\n",
    "n_users = users.shape[0]\n",
    "n_books = books.shape[0]\n",
    "sparsity = 1.0 - len(ratings_new) / float(n_users * n_books)\n",
    "print('The sparsity level of Book Crossing dataset is {:.2%}'.format(sparsity))\n",
    "\n",
    "# Separating explicit and implicit ratings\n",
    "ratings_explicit = ratings_new[ratings_new.bookRating != 0]\n",
    "ratings_implicit = ratings_new[ratings_new.bookRating == 0]\n",
    "\n",
    "# Exploring and handling explicit ratings data\n",
    "users_exp_ratings = users[users.userID.isin(ratings_explicit.userID)]\n",
    "users_imp_ratings = users[users.userID.isin(ratings_implicit.userID)]\n",
    "counts1 = ratings_explicit['userID'].value_counts()\n",
    "ratings_explicit = ratings_explicit[ratings_explicit['userID'].isin(counts1[counts1 >= 1].index)]\n",
    "counts = ratings_explicit['bookRating'].value_counts()\n",
    "ratings_explicit = ratings_explicit[ratings_explicit['bookRating'].isin(counts[counts >= 1].index)]\n",
    "\n",
    "# Generating ratings matrix from explicit ratings table\n",
    "ratings_matrix = ratings_explicit.pivot(index='userID', columns='ISBN', values='bookRating')\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "ratings_matrix = ratings_matrix.astype(np.int32)\n",
    "sparsity = 1.0 - len(ratings_explicit) / float(users_exp_ratings.shape[0] * n_books)\n",
    "print('The sparsity level of Book Crossing dataset is {:.2%}'.format(sparsity))\n",
    "\n",
    "# Setting global variables\n",
    "global metric, k\n",
    "k = 3\n",
    "metric = 'cosine'\n",
    "\n",
    "# Function to find k similar users given the user_id and ratings matrix\n",
    "def findksimilarusers(user_id, ratings, metric=metric, k=k):\n",
    "    similarities = []\n",
    "    indices = []\n",
    "    model_knn = NearestNeighbors(metric=metric, algorithm='brute')\n",
    "    model_knn.fit(ratings)\n",
    "    loc = ratings.index.get_loc(user_id)\n",
    "    distances, indices = model_knn.kneighbors(ratings.iloc[loc, :].values.reshape(1, -1), n_neighbors=k + 1)\n",
    "    similarities = 1 - distances.flatten()\n",
    "    return similarities, indices\n",
    "\n",
    "# Function to predict rating for a specified user-item combination based on user-based approach\n",
    "def predict_userbased(user_id, item_id, ratings, metric=metric, k=k):\n",
    "    prediction = 0\n",
    "    user_loc = ratings.index.get_loc(user_id)\n",
    "    item_loc = ratings.columns.get_loc(item_id)\n",
    "    similarities, indices = findksimilarusers(user_id, ratings, metric, k)\n",
    "    mean_rating = ratings.iloc[user_loc, :].mean()\n",
    "    sum_wt = np.sum(similarities) - 1\n",
    "    product = 1\n",
    "    wtd_sum = 0\n",
    "\n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i] == user_loc:\n",
    "            continue\n",
    "        else:\n",
    "            ratings_diff = ratings.iloc[indices.flatten()[i], item_loc] - np.mean(ratings.iloc[indices.flatten()[i], :])\n",
    "            product = ratings_diff * (similarities[i])\n",
    "            wtd_sum = wtd_sum + product\n",
    "\n",
    "    if sum_wt == 0.0:\n",
    "        sum_wt = 0.1\n",
    "\n",
    "    prediction = int(round(mean_rating + (wtd_sum / sum_wt)))\n",
    "    if prediction <= 0:\n",
    "        prediction = 1\n",
    "    elif prediction > 10:\n",
    "        prediction = 10\n",
    "\n",
    "    print('\\nPredicted rating for user {} -> item {}: {}'.format(user_id, item_id, prediction))\n",
    "    return prediction\n",
    "\n",
    "# Function to find k similar items given the item_id and ratings matrix\n",
    "def findksimilaritems(item_id, ratings, metric=metric, k=k):\n",
    "    similarities = []\n",
    "    indices = []\n",
    "    ratings = ratings.T\n",
    "    loc = ratings.index.get_loc(item_id)\n",
    "    model_knn = NearestNeighbors(metric=metric, algorithm='brute')\n",
    "    model_knn.fit(ratings)\n",
    "\n",
    "    distances, indices = model_knn.kneighbors(ratings.iloc[loc, :].values.reshape(1, -1), n_neighbors=k + 1)\n",
    "    similarities = 1 - distances.flatten()\n",
    "    return similarities, indices\n",
    "\n",
    "# Function to predict rating for a specified user-item combination based on item-based approach\n",
    "def predict_itembased(user_id, item_id, ratings, metric=metric, k=k):\n",
    "    prediction = wtd_sum = 0\n",
    "    user_loc = ratings.index.get_loc(user_id)\n",
    "    item_loc = ratings.columns.get_loc(item_id)\n",
    "    similarities, indices = findksimilaritems(item_id, ratings)\n",
    "    sum_wt = np.sum(similarities) - 1\n",
    "    product = 1\n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i] == item_loc:\n",
    "            continue\n",
    "        else:\n",
    "            product = ratings.iloc[user_loc, indices.flatten()[i]] * (similarities[i])\n",
    "            wtd_sum = wtd_sum + product\n",
    "\n",
    "    if sum_wt == 0.0:\n",
    "        sum_wt = 0.1\n",
    "\n",
    "    prediction = int(round(wtd_sum / sum_wt))\n",
    "\n",
    "    if prediction <= 0:\n",
    "        prediction = 1\n",
    "    elif prediction > 10:\n",
    "       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
